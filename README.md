# Live Project at Times Internet
# OVERVIEW
I led the implementation of DistilBERT, a distilled version of BERT, for intent classification on web- scraped datasets, achieving remarkable accuracy in text data/article categorization aligned with IAB standards. DistilBERT's efficiency and cost-effectiveness played a pivotal role in optimizing the classification process, , showcasing my proficiency in leveraging advanced natural language processing techniques on web-scraped data.
In navigating the challenges associated with web scraping, I adeptly employed efficient techniques for data collection.
Additionally, I designed and implemented production-ready pipelines for real-time projects, including Intent Classification.


# Aman Rai (Project Contributor)
This particular branch, under the stewardship of Aman Rai, serves a pivotal role as a specialized workspace dedicated to the development of a sophisticated text classification model. Our focus is centered around the implementation of IAB categories, aiming to enhance our capabilities in accurately categorizing and analyzing textual content. Through this concerted effort, we aim to achieve a refined level of precision in text classification, contributing to our broader objectives.

# TECHNOLOGY STACK
The technology stack for this project encompass the following components and tools:
1.   ## Programming Language:
 - Python
2.   NLP Libraries:
- NLTK (Natural Language Toolkit): For fundamental NLP tasks such as tokenization, lemmatization, and      part-of-speech tagging.
- spaCy: Known for its speed and efficiency in NLP processing, including named entity recognition.
- Gensim: For topic modeling and document similarity analysis.
- Transformers (Hugging Face): Provides state-of-the-art pre-trained models like BERT, GPT-3, etc., for various   NLP tasks like generate word embeddings, NER, etc.

3.  ## Machine Learning Frameworks:
 - Scikit-Learn: For machine learning tasks related to NLP like classification and clustering.
 - TensorFlow or PyTorch: For building and training deep learning models for NLP tasks.

4.  ## Data Manipulation:
 - Pandas: For data preprocessing, manipulation, and analysis.
 - NumPy: For numerical operations.

5.  ## Data Visualization:
- Matplotlib & Seaborn: For creating visualizations to better understand and present NLP results.

6.  ## Text Preprocessing:
- Regular Expressions: For text cleaning and pattern matching.
- Spacy or NLTK: For more advanced text preprocessing tasks like lemmatization.

7.  ## Web Scraping:
- BeautifulSoup and Selenium: For extracting text data from websites.

8.  ## Version Control:
 - Git: To manage code changes and collaborate with a team.


# Fine_tuned Model 
DistilBERT Model :https://drive.google.com/drive/folders/1-oyXd7Gi5-Ewdw75ktVFtc1cH_JiHqKs?usp=sharing

# Work_Flow
Document :https://docs.google.com/document/d/1uozCVZhifx807VYoQAtQJG40yzRGJDPE/edit#heading=h.gjdgxs

# POC:
Document :https://docs.google.com/document/d/1rvMDttsAZTBJBVFBmHjsZJK8rGnG-l4C/edit

# Contact Details
- Email: amanr3277@gmail.com
- Linkedin: https://www.linkedin.com/in/aman-rai-271496203/
